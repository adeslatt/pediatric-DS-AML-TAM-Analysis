{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f9ac63-1c15-481c-af9a-ba032429149d",
   "metadata": {},
   "source": [
    "# Pediatric DS AML vs TAM\n",
    "\n",
    "DESeq2 Analysis with Kallisto Quantitation Input\n",
    "\n",
    "## Following the Instructions from BioConductor DESeq2 \n",
    "[Transcript abundance to DESeq2 Analysis](https://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#quick-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac92837-8970-4820-8557-342a4993df84",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transcript abundance files and tximport / tximeta\n",
    "\n",
    "Our recommended pipeline for DESeq2 is to use fast transcript abundance quantifiers upstream of DESeq2, and then to create gene-level count matrices for use with DESeq2 by importing the quantification data using tximport (Soneson, Love, and Robinson 2015). This workflow allows users to import transcript abundance estimates from a variety of external software, including the following methods:\n",
    "\n",
    "* [Salmon](http://combine-lab.github.io/salmon/) (Patro et al. 2017)\n",
    "* [Sailfish](http://www.cs.cmu.edu/~ckingsf/software/sailfish/) (Patro, Mount, and Kingsford 2014)\n",
    "* [kallisto](https://pachterlab.github.io/kallisto/about.html) (Bray et al. 2016)\n",
    "* [RSEM](http://deweylab.github.io/RSEM/) (Li and Dewey 2011)\n",
    "\n",
    "Some advantages of using the above methods for transcript abundance estimation are: \n",
    "* (i) this approach corrects for potential changes in gene length across samples (e.g. from differential isoform usage) (Trapnell et al. 2013), \n",
    "* (ii) some of these methods (Salmon, Sailfish, kallisto) are substantially faster and require less memory and disk usage compared to alignment-based methods that require creation and storage of BAM files, and \n",
    "* (iii) it is possible to avoid discarding those fragments that can align to multiple genes with homologous sequence, thus increasing sensitivity (Robert and Watson 2015).\n",
    "\n",
    "Full details on the motivation and methods for importing transcript level abundance and count estimates, summarizing to gene-level count matrices and producing an offset which corrects for potential changes in average transcript length across samples are described in (Soneson, Love, and Robinson 2015). Note that the tximport-to-DESeq2 approach uses estimated gene counts from the transcript abundance quantifiers, but not normalized counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f50203a6-0b7e-4e70-8bd1-39ca8cad55c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"readr\")\n",
    "library(\"readr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d288d00-c591-4fab-8261-37fe14b883c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'getOption(\"repos\")' replaces Bioconductor standard repositories, see\n",
      "'?repositories' for details\n",
      "\n",
      "replacement repositories:\n",
      "    CRAN: https://cran.r-project.org\n",
      "\n",
      "\n",
      "Bioconductor version 3.14 (BiocManager 1.30.18), R 4.1.1 (2021-08-10)\n",
      "\n",
      "Warning message:\n",
      "“package(s) not installed when version(s) same as current; use `force = TRUE` to\n",
      "  re-install: 'tximport'”\n",
      "Old packages: 'backports', 'blob', 'brew', 'brio', 'broom', 'bslib', 'callr',\n",
      "  'caret', 'class', 'clipr', 'colorspace', 'commonmark', 'conflicted', 'covr',\n",
      "  'cpp11', 'crayon', 'credentials', 'crosstalk', 'curl', 'data.table', 'DBI',\n",
      "  'dbplyr', 'desc', 'devtools', 'dials', 'diffobj', 'digest', 'dplyr', 'DT',\n",
      "  'dtplyr', 'e1071', 'evaluate', 'fansi', 'farver', 'forcats', 'foreach',\n",
      "  'forecast', 'fs', 'furrr', 'future', 'future.apply', 'gargle', 'generics',\n",
      "  'gert', 'ggplot2', 'gh', 'git2r', 'gitcreds', 'globals', 'glue',\n",
      "  'googlesheets4', 'gower', 'gtable', 'hardhat', 'haven', 'hms', 'htmltools',\n",
      "  'httpuv', 'httr', 'infer', 'ipred', 'IRdisplay', 'IRkernel', 'isoband',\n",
      "  'iterators', 'jsonlite', 'knitr', 'later', 'lattice', 'lhs', 'lifecycle',\n",
      "  'lmtest', 'lubridate', 'magrittr', 'MASS', 'Matrix', 'memoise', 'mgcv',\n",
      "  'mime', 'modeldata', 'modelr', 'nlme', 'nnet', 'objectProperties',\n",
      "  'objectSignals', 'openssl', 'parallelly', 'parsnip', 'patchwork', 'pbdZMQ',\n",
      "  'pillar', 'pkgbuild', 'pkgload', 'plyr', 'processx', 'progressr', 'proxy',\n",
      "  'ps', 'purrr', 'quantmod', 'randomForest', 'rcmdcheck', 'RColorBrewer',\n",
      "  'Rcpp', 'RcppArmadillo', 'RCurl', 'readxl', 'recipes', 'remotes', 'repr',\n",
      "  'reprex', 'rex', 'rlang', 'rmarkdown', 'RODBC', 'roxygen2', 'rpart',\n",
      "  'rprojroot', 'rsample', 'RSQLite', 'rstudioapi', 'rversions', 'rvest',\n",
      "  'S4Vectors', 'sass', 'scales', 'sessioninfo', 'sevenbridges', 'shiny',\n",
      "  'stringi', 'stringr', 'survival', 'sys', 'testthat', 'tibble', 'tidymodels',\n",
      "  'tidyr', 'tidyselect', 'tidyverse', 'timeDate', 'tinytex', 'tseries', 'TTR',\n",
      "  'tune', 'tzdb', 'urca', 'usethis', 'uuid', 'vctrs', 'viridisLite', 'waldo',\n",
      "  'withr', 'workflows', 'workflowsets', 'xfun', 'xml2', 'xts', 'yaml',\n",
      "  'yardstick', 'zip', 'zoo'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BiocManager::install(\"tximport\")\n",
    "library(tximport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcf092df-b897-4fdb-b004-a1d9b3ed2b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in seq_len(head.end.idx):\n",
      "“first element used of 'length.out' argument”\n",
      "ERROR while rich displaying an object: Error in seq_len(head.end.idx): argument must be coercible to non-negative integer\n",
      "\n",
      "Traceback:\n",
      "1. FUN(X[[i]], ...)\n",
      "2. tryCatch(withCallingHandlers({\n",
      " .     if (!mime %in% names(repr::mime2repr)) \n",
      " .         stop(\"No repr_* for mimetype \", mime, \" in repr::mime2repr\")\n",
      " .     rpr <- repr::mime2repr[[mime]](obj)\n",
      " .     if (is.null(rpr)) \n",
      " .         return(NULL)\n",
      " .     prepare_content(is.raw(rpr), rpr)\n",
      " . }, error = error_handler), error = outer_handler)\n",
      "3. tryCatchList(expr, classes, parentenv, handlers)\n",
      "4. tryCatchOne(expr, names, parentenv, handlers[[1L]])\n",
      "5. doTryCatch(return(expr), name, parentenv, handler)\n",
      "6. withCallingHandlers({\n",
      " .     if (!mime %in% names(repr::mime2repr)) \n",
      " .         stop(\"No repr_* for mimetype \", mime, \" in repr::mime2repr\")\n",
      " .     rpr <- repr::mime2repr[[mime]](obj)\n",
      " .     if (is.null(rpr)) \n",
      " .         return(NULL)\n",
      " .     prepare_content(is.raw(rpr), rpr)\n",
      " . }, error = error_handler)\n",
      "7. repr::mime2repr[[mime]](obj)\n",
      "8. repr_html.help_files_with_topic(obj)\n",
      "9. repr_help_files_with_topic_generic(obj, Rd2HTML)\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{tximport}{Import transcript-level abundances and counts for transcript- and gene-level analysis packages}{tximport}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "\\code{tximport} imports transcript-level estimates from various\n",
       "external software and optionally summarizes abundances, counts,\n",
       "and transcript lengths\n",
       "to the gene-level (default) or outputs transcript-level matrices\n",
       "(see \\code{txOut} argument).\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "tximport(\n",
       "  files,\n",
       "  type = c(\"none\", \"salmon\", \"sailfish\", \"alevin\", \"kallisto\", \"rsem\", \"stringtie\"),\n",
       "  txIn = TRUE,\n",
       "  txOut = FALSE,\n",
       "  countsFromAbundance = c(\"no\", \"scaledTPM\", \"lengthScaledTPM\", \"dtuScaledTPM\"),\n",
       "  tx2gene = NULL,\n",
       "  varReduce = FALSE,\n",
       "  dropInfReps = FALSE,\n",
       "  infRepStat = NULL,\n",
       "  ignoreTxVersion = FALSE,\n",
       "  ignoreAfterBar = FALSE,\n",
       "  geneIdCol,\n",
       "  txIdCol,\n",
       "  abundanceCol,\n",
       "  countsCol,\n",
       "  lengthCol,\n",
       "  importer = NULL,\n",
       "  existenceOptional = FALSE,\n",
       "  sparse = FALSE,\n",
       "  sparseThreshold = 1,\n",
       "  readLength = 75,\n",
       "  alevinArgs = NULL\n",
       ")\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{files}] a character vector of filenames for the transcript-level abundances\n",
       "\n",
       "\\item[\\code{type}] character, the type of software used to generate the abundances.\n",
       "Options are \"salmon\", \"sailfish\", \"alevin\", \"kallisto\", \"rsem\", \"stringtie\", or \"none\".\n",
       "This argument is used to autofill the arguments below (geneIdCol, etc.)\n",
       "\"none\" means that the user will specify these columns. Be aware that\n",
       "specifying \\code{type} other than \"none\" will ignore the arguments below\n",
       "(geneIdCol, etc.)\n",
       "\n",
       "\\item[\\code{txIn}] logical, whether the incoming files are transcript level (default TRUE)\n",
       "\n",
       "\\item[\\code{txOut}] logical, whether the function should just output\n",
       "transcript-level (default FALSE)\n",
       "\n",
       "\\item[\\code{countsFromAbundance}] character, either \"no\" (default), \"scaledTPM\",\n",
       "\"lengthScaledTPM\", or \"dtuScaledTPM\".\n",
       "Whether to generate estimated counts using abundance estimates:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item{} scaled up to library size (scaledTPM),\n",
       "\\item{} scaled using the average transcript length over samples\n",
       "and then the library size (lengthScaledTPM), or\n",
       "\\item{} scaled using the median transcript length among isoforms of a gene,\n",
       "and then the library size (dtuScaledTPM). \n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "dtuScaledTPM is designed for DTU analysis in combination with \\code{txOut=TRUE},\n",
       "and it requires specifing a \\code{tx2gene} data.frame.\n",
       "dtuScaledTPM works such that within a gene, values from all samples and\n",
       "all transcripts get scaled by the same fixed median transcript length.\n",
       "If using scaledTPM, lengthScaledTPM, or geneLengthScaledTPM, \n",
       "the counts are no longer correlated across samples with transcript length,\n",
       "and so the length offset matrix should not be used.\n",
       "\n",
       "\\item[\\code{tx2gene}] a two-column data.frame linking transcript id (column 1)\n",
       "to gene id (column 2).\n",
       "the column names are not relevant, but this column order must be used. \n",
       "this argument is required for gene-level summarization, and the tximport\n",
       "vignette describes how to construct this data.frame (see Details below).\n",
       "An automated solution to avoid having to create \\code{tx2gene} if\n",
       "one has quantified with Salmon or alevin with human or mouse transcriptomes\n",
       "is to use the \\code{tximeta} function from the tximeta Bioconductor package.\n",
       "\n",
       "\\item[\\code{varReduce}] whether to reduce per-sample inferential replicates\n",
       "information into a matrix of sample variances \\code{variance} (default FALSE).\n",
       "alevin computes inferential variance by default for bootstrap\n",
       "inferential replicates, so this argument is ignored/not necessary\n",
       "\n",
       "\\item[\\code{dropInfReps}] whether to skip reading in inferential replicates\n",
       "(default FALSE). For alevin, \\code{tximport} will still read in the\n",
       "inferential variance matrix if it exists\n",
       "\n",
       "\\item[\\code{infRepStat}] a function to re-compute counts and abundances from the\n",
       "inferential replicates, e.g. \\code{matrixStats::rowMedians} to re-compute counts \n",
       "as the median of the inferential replicates. The order of operations is:\n",
       "first counts are re-computed, then abundances are re-computed.\n",
       "Following this, if \\code{countsFromAbundance} is not \"no\",\n",
       "\\code{tximport} will again re-compute counts from the re-computed abundances.\n",
       "\\code{infRepStat} should operate on rows of a matrix. (default is NULL)\n",
       "\n",
       "\\item[\\code{ignoreTxVersion}] logical, whether to split the tx id on the '.' character\n",
       "to remove version information to facilitate matching with the tx id in \\code{tx2gene}\n",
       "(default FALSE)\n",
       "\n",
       "\\item[\\code{ignoreAfterBar}] logical, whether to split the tx id on the '|' character\n",
       "to facilitate matching with the tx id in \\code{tx2gene} (default FALSE).\n",
       "if \\code{txOut=TRUE} it will strip the text after '|' on the rownames\n",
       "of the matrices\n",
       "\n",
       "\\item[\\code{geneIdCol}] name of column with gene id. if missing, the \\code{tx2gene}\n",
       "argument can be used. Note that this argument and the other four \"...Col\"\n",
       "arguments below are ignored unless \\code{type=\"none\"}\n",
       "\n",
       "\\item[\\code{txIdCol}] name of column with tx id\n",
       "\n",
       "\\item[\\code{abundanceCol}] name of column with abundances (e.g. TPM or FPKM)\n",
       "\n",
       "\\item[\\code{countsCol}] name of column with estimated counts\n",
       "\n",
       "\\item[\\code{lengthCol}] name of column with feature length information\n",
       "\n",
       "\\item[\\code{importer}] a function used to read in the files\n",
       "\n",
       "\\item[\\code{existenceOptional}] logical, should tximport not check if files exist before attempting\n",
       "import (default FALSE, meaning files must exist according to \\code{file.exists})\n",
       "\n",
       "\\item[\\code{sparse}] logical, whether to try to import data sparsely (default is FALSE).\n",
       "Initial implementation for \\code{txOut=TRUE}, \\code{countsFromAbundance=\"no\"}\n",
       "or \\code{\"scaledTPM\"}, no inferential replicates. Only counts matrix\n",
       "is returned (and abundance matrix if using \\code{\"scaledTPM\"})\n",
       "\n",
       "\\item[\\code{sparseThreshold}] the minimum threshold for including a count as a\n",
       "non-zero count during sparse import (default is 1)\n",
       "\n",
       "\\item[\\code{readLength}] numeric, the read length used to calculate counts from\n",
       "StringTie's output of coverage. Default value (from StringTie) is 75.\n",
       "The formula used to calculate counts is:\n",
       "\\code{cov * transcript length / read length}\n",
       "\n",
       "\\item[\\code{alevinArgs}] named list, with logical elements \\code{filterBarcodes},\n",
       "\\code{tierImport}, \\code{forceSlow}, \\code{dropMeanVar}.\n",
       "See Details for definitions.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "\\strong{Inferential replicates:}\n",
       "\\code{tximport} will also load in information about inferential replicates --\n",
       "a list of matrices of the Gibbs samples from the posterior, or bootstrap replicates,\n",
       "per sample -- if these data are available in the expected locations relative\n",
       "to the \\code{files}.\n",
       "The inferential replicates, stored in \\code{infReps} in the output list,\n",
       "are on estimated counts, and therefore follow \\code{counts} in the output list.\n",
       "By setting \\code{varReduce=TRUE}, the inferential replicate matrices\n",
       "will be replaced by a single matrix with the sample variance per transcript/gene\n",
       "and per sample.\n",
       "\n",
       "\\strong{summarizeToGene:}\n",
       "While \\code{tximport} summarizes to the gene-level by default, \n",
       "the user can also perform the import and summarization steps manually,\n",
       "by specifing \\code{txOut=TRUE} and then using the function \\code{summarizeToGene}.\n",
       "Note however that this is equivalent to \\code{tximport} with\n",
       "\\code{txOut=FALSE} (the default).\n",
       "\n",
       "\\strong{Solutions on summarization:} regarding \\code{\"tximport failed at summarizing to the gene-level\"}:\n",
       "\n",
       "\\begin{enumerate}\n",
       "\n",
       "\\item{} provide a \\code{tx2gene} data.frame linking transcripts to genes (more below)\n",
       "\\item{} avoid gene-level summarization by specifying \\code{txOut=TRUE}\n",
       "\n",
       "\\end{enumerate}\n",
       "\n",
       "\n",
       "See \\code{vignette('tximport')} for example code for generating a\n",
       "\\code{tx2gene} data.frame from a \\code{TxDb} object.\n",
       "The \\code{tx2gene} data.frame should exactly match and be derived from\n",
       "the same set of transcripts used for quantifying (the set of transcript\n",
       "used to create the transcriptome index).\n",
       "\n",
       "\\strong{Tximeta:}\n",
       "One automated solution for Salmon or alevin quantification data is to use the\n",
       "\\code{tximeta} function in the tximeta Bioconductor package\n",
       "which builds upon and extends \\code{tximport}; this solution should\n",
       "work out-of-the-box for human and mouse transcriptomes downloaded\n",
       "from GENCODE, Ensembl, or RefSeq. For other cases, the user\n",
       "should create the \\code{tx2gene} manually as shown in the tximport\n",
       "vignette.\n",
       "\n",
       "\\strong{On tx2gene construction:}\n",
       "Note that the \\code{keys} and \\code{select} functions used\n",
       "to create the \\code{tx2gene} object are documented\n",
       "in the man page for \\LinkA{AnnotationDb-class}{AnnotationDb.Rdash.class} objects\n",
       "in the AnnotationDbi package (TxDb inherits from AnnotationDb).\n",
       "For further details on generating TxDb objects from various inputs\n",
       "see \\code{vignette('GenomicFeatures')} from the GenomicFeatures package.\n",
       "\n",
       "\\strong{alevin:}\n",
       "The \\code{alevinArgs} argument includes some alevin-specific arguments.\n",
       "This optional argument is a list with any or all of the following named logical variables:\n",
       "\\code{filterBarcodes}, \\code{tierImport}, and \\code{forceSlow}.\n",
       "The variables are described as follows (with default values in parens):\n",
       "\\code{filterBarcodes} (FALSE) import only cell barcodes listed in\n",
       "\\code{whitelist.txt};\n",
       "\\code{tierImport} (FALSE) import the tier information in addition to counts;\n",
       "\\code{forceSlow} (FALSE) force the use of the slower import R code\n",
       "even if \\code{fishpond} is installed;\n",
       "\\code{dropMeanVar} (FALSE) don't import inferential mean and variance\n",
       "matrices even if they exist (also skips inferential replicates)\n",
       "For \\code{type=\"alevin\"} all arguments other than \\code{files},\n",
       "\\code{dropInfReps}, and \\code{alevinArgs} are ignored.\n",
       "Note that \\code{files} should point to a single \\code{quants\\_mat.gz} file,\n",
       "in the directory structure created by the alevin software\n",
       "(e.g. do not move the file or delete the other important files).\n",
       "Note that importing alevin quantifications will be much faster by first\n",
       "installing the \\code{fishpond} package, which contains a C++ importer\n",
       "for alevin's EDS format.\n",
       "For alevin, \\code{tximport} is importing the gene-by-cell matrix of counts,\n",
       "as \\code{txi\\$counts}, and effective lengths are not estimated.\n",
       "\\code{txi\\$mean} and \\code{txi\\$variance} may also be imported if\n",
       "inferential replicates were used, as well as inferential replicates\n",
       "if these were output by alevin.\n",
       "Length correction should not be applied to datasets where there\n",
       "is not an expected correlation of counts and feature length.\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "A simple list containing matrices: abundance, counts, length.\n",
       "Another list element 'countsFromAbundance' carries through\n",
       "the character argument used in the tximport call.\n",
       "The length matrix contains the average transcript length for each\n",
       "gene which can be used as an offset for gene-level analysis.\n",
       "If detected, and \\code{txOut=TRUE}, inferential replicates for\n",
       "each sample will be imported and stored as a list of matrices,\n",
       "itself an element \\code{infReps} in the returned list.\n",
       "An exception is alevin, in which the \\code{infReps} are a list\n",
       "of bootstrap replicate matrices, where each matrix has\n",
       "genes as rows and cells as columns.\n",
       "If \\code{varReduce=TRUE} the inferential replicates will be summarized\n",
       "according to the sample variance, and stored as a matrix \\code{variance}.\n",
       "alevin already computes the variance of the bootstrap inferential replicates\n",
       "and so this is imported without needing to specify \\code{varReduce=TRUE}.\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "Charlotte Soneson, Michael I. Love, Mark D. Robinson (2015)\n",
       "Differential analyses for RNA-seq: transcript-level estimates\n",
       "improve gene-level inferences. F1000Research.\n",
       "\\url{http://doi.org/10.12688/f1000research.7563}\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "\n",
       "# load data for demonstrating tximport\n",
       "# note that the vignette shows more examples\n",
       "# including how to read in files quickly using the readr package\n",
       "\n",
       "library(tximportData)\n",
       "dir <- system.file(\"extdata\", package=\"tximportData\")\n",
       "samples <- read.table(file.path(dir,\"samples.txt\"), header=TRUE)\n",
       "files <- file.path(dir,\"salmon\", samples$run, \"quant.sf.gz\")\n",
       "names(files) <- paste0(\"sample\",1:6)\n",
       "\n",
       "# tx2gene links transcript IDs to gene IDs for summarization\n",
       "tx2gene <- read.csv(file.path(dir, \"tx2gene.gencode.v27.csv\"))\n",
       "\n",
       "txi <- tximport(files, type=\"salmon\", tx2gene=tx2gene)\n",
       "\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "tximport               package:tximport                R Documentation\n",
       "\n",
       "_\bI_\bm_\bp_\bo_\br_\bt _\bt_\br_\ba_\bn_\bs_\bc_\br_\bi_\bp_\bt-_\bl_\be_\bv_\be_\bl _\ba_\bb_\bu_\bn_\bd_\ba_\bn_\bc_\be_\bs _\ba_\bn_\bd _\bc_\bo_\bu_\bn_\bt_\bs _\bf_\bo_\br _\bt_\br_\ba_\bn_\bs_\bc_\br_\bi_\bp_\bt- _\ba_\bn_\bd\n",
       "_\bg_\be_\bn_\be-_\bl_\be_\bv_\be_\bl _\ba_\bn_\ba_\bl_\by_\bs_\bi_\bs _\bp_\ba_\bc_\bk_\ba_\bg_\be_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     ‘tximport’ imports transcript-level estimates from various\n",
       "     external software and optionally summarizes abundances, counts,\n",
       "     and transcript lengths to the gene-level (default) or outputs\n",
       "     transcript-level matrices (see ‘txOut’ argument).\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     tximport(\n",
       "       files,\n",
       "       type = c(\"none\", \"salmon\", \"sailfish\", \"alevin\", \"kallisto\", \"rsem\", \"stringtie\"),\n",
       "       txIn = TRUE,\n",
       "       txOut = FALSE,\n",
       "       countsFromAbundance = c(\"no\", \"scaledTPM\", \"lengthScaledTPM\", \"dtuScaledTPM\"),\n",
       "       tx2gene = NULL,\n",
       "       varReduce = FALSE,\n",
       "       dropInfReps = FALSE,\n",
       "       infRepStat = NULL,\n",
       "       ignoreTxVersion = FALSE,\n",
       "       ignoreAfterBar = FALSE,\n",
       "       geneIdCol,\n",
       "       txIdCol,\n",
       "       abundanceCol,\n",
       "       countsCol,\n",
       "       lengthCol,\n",
       "       importer = NULL,\n",
       "       existenceOptional = FALSE,\n",
       "       sparse = FALSE,\n",
       "       sparseThreshold = 1,\n",
       "       readLength = 75,\n",
       "       alevinArgs = NULL\n",
       "     )\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "   files: a character vector of filenames for the transcript-level\n",
       "          abundances\n",
       "\n",
       "    type: character, the type of software used to generate the\n",
       "          abundances. Options are \"salmon\", \"sailfish\", \"alevin\",\n",
       "          \"kallisto\", \"rsem\", \"stringtie\", or \"none\". This argument is\n",
       "          used to autofill the arguments below (geneIdCol, etc.) \"none\"\n",
       "          means that the user will specify these columns. Be aware that\n",
       "          specifying ‘type’ other than \"none\" will ignore the arguments\n",
       "          below (geneIdCol, etc.)\n",
       "\n",
       "    txIn: logical, whether the incoming files are transcript level\n",
       "          (default TRUE)\n",
       "\n",
       "   txOut: logical, whether the function should just output\n",
       "          transcript-level (default FALSE)\n",
       "\n",
       "countsFromAbundance: character, either \"no\" (default), \"scaledTPM\",\n",
       "          \"lengthScaledTPM\", or \"dtuScaledTPM\". Whether to generate\n",
       "          estimated counts using abundance estimates:\n",
       "\n",
       "            • scaled up to library size (scaledTPM),\n",
       "\n",
       "            • scaled using the average transcript length over samples\n",
       "              and then the library size (lengthScaledTPM), or\n",
       "\n",
       "            • scaled using the median transcript length among isoforms\n",
       "              of a gene, and then the library size (dtuScaledTPM).\n",
       "\n",
       "          dtuScaledTPM is designed for DTU analysis in combination with\n",
       "          ‘txOut=TRUE’, and it requires specifing a ‘tx2gene’\n",
       "          data.frame. dtuScaledTPM works such that within a gene,\n",
       "          values from all samples and all transcripts get scaled by the\n",
       "          same fixed median transcript length. If using scaledTPM,\n",
       "          lengthScaledTPM, or geneLengthScaledTPM, the counts are no\n",
       "          longer correlated across samples with transcript length, and\n",
       "          so the length offset matrix should not be used.\n",
       "\n",
       " tx2gene: a two-column data.frame linking transcript id (column 1) to\n",
       "          gene id (column 2). the column names are not relevant, but\n",
       "          this column order must be used.  this argument is required\n",
       "          for gene-level summarization, and the tximport vignette\n",
       "          describes how to construct this data.frame (see Details\n",
       "          below). An automated solution to avoid having to create\n",
       "          ‘tx2gene’ if one has quantified with Salmon or alevin with\n",
       "          human or mouse transcriptomes is to use the ‘tximeta’\n",
       "          function from the tximeta Bioconductor package.\n",
       "\n",
       "varReduce: whether to reduce per-sample inferential replicates\n",
       "          information into a matrix of sample variances ‘variance’\n",
       "          (default FALSE). alevin computes inferential variance by\n",
       "          default for bootstrap inferential replicates, so this\n",
       "          argument is ignored/not necessary\n",
       "\n",
       "dropInfReps: whether to skip reading in inferential replicates (default\n",
       "          FALSE). For alevin, ‘tximport’ will still read in the\n",
       "          inferential variance matrix if it exists\n",
       "\n",
       "infRepStat: a function to re-compute counts and abundances from the\n",
       "          inferential replicates, e.g. ‘matrixStats::rowMedians’ to\n",
       "          re-compute counts as the median of the inferential\n",
       "          replicates. The order of operations is: first counts are\n",
       "          re-computed, then abundances are re-computed. Following this,\n",
       "          if ‘countsFromAbundance’ is not \"no\", ‘tximport’ will again\n",
       "          re-compute counts from the re-computed abundances.\n",
       "          ‘infRepStat’ should operate on rows of a matrix. (default is\n",
       "          NULL)\n",
       "\n",
       "ignoreTxVersion: logical, whether to split the tx id on the '.'\n",
       "          character to remove version information to facilitate\n",
       "          matching with the tx id in ‘tx2gene’ (default FALSE)\n",
       "\n",
       "ignoreAfterBar: logical, whether to split the tx id on the '|'\n",
       "          character to facilitate matching with the tx id in ‘tx2gene’\n",
       "          (default FALSE). if ‘txOut=TRUE’ it will strip the text after\n",
       "          '|' on the rownames of the matrices\n",
       "\n",
       "geneIdCol: name of column with gene id. if missing, the ‘tx2gene’\n",
       "          argument can be used. Note that this argument and the other\n",
       "          four \"...Col\" arguments below are ignored unless\n",
       "          ‘type=\"none\"’\n",
       "\n",
       " txIdCol: name of column with tx id\n",
       "\n",
       "abundanceCol: name of column with abundances (e.g. TPM or FPKM)\n",
       "\n",
       "countsCol: name of column with estimated counts\n",
       "\n",
       "lengthCol: name of column with feature length information\n",
       "\n",
       "importer: a function used to read in the files\n",
       "\n",
       "existenceOptional: logical, should tximport not check if files exist\n",
       "          before attempting import (default FALSE, meaning files must\n",
       "          exist according to ‘file.exists’)\n",
       "\n",
       "  sparse: logical, whether to try to import data sparsely (default is\n",
       "          FALSE). Initial implementation for ‘txOut=TRUE’,\n",
       "          ‘countsFromAbundance=\"no\"’ or ‘\"scaledTPM\"’, no inferential\n",
       "          replicates. Only counts matrix is returned (and abundance\n",
       "          matrix if using ‘\"scaledTPM\"’)\n",
       "\n",
       "sparseThreshold: the minimum threshold for including a count as a\n",
       "          non-zero count during sparse import (default is 1)\n",
       "\n",
       "readLength: numeric, the read length used to calculate counts from\n",
       "          StringTie's output of coverage. Default value (from\n",
       "          StringTie) is 75. The formula used to calculate counts is:\n",
       "          ‘cov * transcript length / read length’\n",
       "\n",
       "alevinArgs: named list, with logical elements ‘filterBarcodes’,\n",
       "          ‘tierImport’, ‘forceSlow’, ‘dropMeanVar’. See Details for\n",
       "          definitions.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     *Inferential replicates:* ‘tximport’ will also load in information\n",
       "     about inferential replicates - a list of matrices of the Gibbs\n",
       "     samples from the posterior, or bootstrap replicates, per sample -\n",
       "     if these data are available in the expected locations relative to\n",
       "     the ‘files’. The inferential replicates, stored in ‘infReps’ in\n",
       "     the output list, are on estimated counts, and therefore follow\n",
       "     ‘counts’ in the output list. By setting ‘varReduce=TRUE’, the\n",
       "     inferential replicate matrices will be replaced by a single matrix\n",
       "     with the sample variance per transcript/gene and per sample.\n",
       "\n",
       "     *summarizeToGene:* While ‘tximport’ summarizes to the gene-level\n",
       "     by default, the user can also perform the import and summarization\n",
       "     steps manually, by specifing ‘txOut=TRUE’ and then using the\n",
       "     function ‘summarizeToGene’. Note however that this is equivalent\n",
       "     to ‘tximport’ with ‘txOut=FALSE’ (the default).\n",
       "\n",
       "     *Solutions on summarization:* regarding ‘\"tximport failed at\n",
       "     summarizing to the gene-level\"’:\n",
       "\n",
       "       1. provide a ‘tx2gene’ data.frame linking transcripts to genes\n",
       "          (more below)\n",
       "\n",
       "       2. avoid gene-level summarization by specifying ‘txOut=TRUE’\n",
       "\n",
       "     See ‘vignette('tximport')’ for example code for generating a\n",
       "     ‘tx2gene’ data.frame from a ‘TxDb’ object. The ‘tx2gene’\n",
       "     data.frame should exactly match and be derived from the same set\n",
       "     of transcripts used for quantifying (the set of transcript used to\n",
       "     create the transcriptome index).\n",
       "\n",
       "     *Tximeta:* One automated solution for Salmon or alevin\n",
       "     quantification data is to use the ‘tximeta’ function in the\n",
       "     tximeta Bioconductor package which builds upon and extends\n",
       "     ‘tximport’; this solution should work out-of-the-box for human and\n",
       "     mouse transcriptomes downloaded from GENCODE, Ensembl, or RefSeq.\n",
       "     For other cases, the user should create the ‘tx2gene’ manually as\n",
       "     shown in the tximport vignette.\n",
       "\n",
       "     *On tx2gene construction:* Note that the ‘keys’ and ‘select’\n",
       "     functions used to create the ‘tx2gene’ object are documented in\n",
       "     the man page for AnnotationDb-class objects in the AnnotationDbi\n",
       "     package (TxDb inherits from AnnotationDb). For further details on\n",
       "     generating TxDb objects from various inputs see\n",
       "     ‘vignette('GenomicFeatures')’ from the GenomicFeatures package.\n",
       "\n",
       "     *alevin:* The ‘alevinArgs’ argument includes some alevin-specific\n",
       "     arguments. This optional argument is a list with any or all of the\n",
       "     following named logical variables: ‘filterBarcodes’, ‘tierImport’,\n",
       "     and ‘forceSlow’. The variables are described as follows (with\n",
       "     default values in parens): ‘filterBarcodes’ (FALSE) import only\n",
       "     cell barcodes listed in ‘whitelist.txt’; ‘tierImport’ (FALSE)\n",
       "     import the tier information in addition to counts; ‘forceSlow’\n",
       "     (FALSE) force the use of the slower import R code even if\n",
       "     ‘fishpond’ is installed; ‘dropMeanVar’ (FALSE) don't import\n",
       "     inferential mean and variance matrices even if they exist (also\n",
       "     skips inferential replicates) For ‘type=\"alevin\"’ all arguments\n",
       "     other than ‘files’, ‘dropInfReps’, and ‘alevinArgs’ are ignored.\n",
       "     Note that ‘files’ should point to a single ‘quants_mat.gz’ file,\n",
       "     in the directory structure created by the alevin software (e.g. do\n",
       "     not move the file or delete the other important files). Note that\n",
       "     importing alevin quantifications will be much faster by first\n",
       "     installing the ‘fishpond’ package, which contains a C++ importer\n",
       "     for alevin's EDS format. For alevin, ‘tximport’ is importing the\n",
       "     gene-by-cell matrix of counts, as ‘txi$counts’, and effective\n",
       "     lengths are not estimated. ‘txi$mean’ and ‘txi$variance’ may also\n",
       "     be imported if inferential replicates were used, as well as\n",
       "     inferential replicates if these were output by alevin. Length\n",
       "     correction should not be applied to datasets where there is not an\n",
       "     expected correlation of counts and feature length.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     A simple list containing matrices: abundance, counts, length.\n",
       "     Another list element 'countsFromAbundance' carries through the\n",
       "     character argument used in the tximport call. The length matrix\n",
       "     contains the average transcript length for each gene which can be\n",
       "     used as an offset for gene-level analysis. If detected, and\n",
       "     ‘txOut=TRUE’, inferential replicates for each sample will be\n",
       "     imported and stored as a list of matrices, itself an element\n",
       "     ‘infReps’ in the returned list. An exception is alevin, in which\n",
       "     the ‘infReps’ are a list of bootstrap replicate matrices, where\n",
       "     each matrix has genes as rows and cells as columns. If\n",
       "     ‘varReduce=TRUE’ the inferential replicates will be summarized\n",
       "     according to the sample variance, and stored as a matrix\n",
       "     ‘variance’. alevin already computes the variance of the bootstrap\n",
       "     inferential replicates and so this is imported without needing to\n",
       "     specify ‘varReduce=TRUE’.\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Charlotte Soneson, Michael I. Love, Mark D. Robinson (2015)\n",
       "     Differential analyses for RNA-seq: transcript-level estimates\n",
       "     improve gene-level inferences. F1000Research. <URL:\n",
       "     http://doi.org/10.12688/f1000research.7563>\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     # load data for demonstrating tximport\n",
       "     # note that the vignette shows more examples\n",
       "     # including how to read in files quickly using the readr package\n",
       "     \n",
       "     library(tximportData)\n",
       "     dir <- system.file(\"extdata\", package=\"tximportData\")\n",
       "     samples <- read.table(file.path(dir,\"samples.txt\"), header=TRUE)\n",
       "     files <- file.path(dir,\"salmon\", samples$run, \"quant.sf.gz\")\n",
       "     names(files) <- paste0(\"sample\",1:6)\n",
       "     \n",
       "     # tx2gene links transcript IDs to gene IDs for summarization\n",
       "     tx2gene <- read.csv(file.path(dir, \"tx2gene.gencode.v27.csv\"))\n",
       "     \n",
       "     txi <- tximport(files, type=\"salmon\", tx2gene=tx2gene)\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?tximport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d119c278-75b7-45e3-abb5-67a053799801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"cowplot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b8a8225-747e-491f-accd-d23f035028e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"cowplot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f11fb1c-4377-42a2-84ec-48029872462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n",
      "'getOption(\"repos\")' replaces Bioconductor standard repositories, see\n",
      "'?repositories' for details\n",
      "\n",
      "replacement repositories:\n",
      "    CRAN: https://cran.r-project.org\n",
      "\n",
      "\n",
      "Bioconductor version 3.14 (BiocManager 1.30.18), R 4.1.1 (2021-08-10)\n",
      "\n",
      "Installing package(s) 'BiocVersion'\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n",
      "Old packages: 'backports', 'BiocGenerics', 'blob', 'brew', 'brio', 'broom',\n",
      "  'bslib', 'callr', 'caret', 'class', 'cli', 'clipr', 'colorspace',\n",
      "  'commonmark', 'conflicted', 'covr', 'cpp11', 'crayon', 'credentials',\n",
      "  'crosstalk', 'curl', 'data.table', 'DBI', 'dbplyr', 'desc', 'devtools',\n",
      "  'dials', 'diffobj', 'digest', 'dplyr', 'DT', 'dtplyr', 'e1071', 'evaluate',\n",
      "  'fansi', 'farver', 'forcats', 'foreach', 'forecast', 'fs', 'furrr', 'future',\n",
      "  'future.apply', 'gargle', 'generics', 'gert', 'ggplot2', 'gh', 'git2r',\n",
      "  'gitcreds', 'globals', 'glue', 'googlesheets4', 'gower', 'gtable', 'hardhat',\n",
      "  'haven', 'hms', 'htmltools', 'httpuv', 'httr', 'infer', 'ipred', 'IRdisplay',\n",
      "  'IRkernel', 'isoband', 'iterators', 'jsonlite', 'knitr', 'later', 'lattice',\n",
      "  'lhs', 'lifecycle', 'lmtest', 'lubridate', 'magrittr', 'MASS', 'Matrix',\n",
      "  'memoise', 'mgcv', 'mime', 'modeldata', 'modelr', 'nlme', 'nnet',\n",
      "  'objectProperties', 'objectSignals', 'openssl', 'parallelly', 'parsnip',\n",
      "  'patchwork', 'pbdZMQ', 'pillar', 'pkgbuild', 'pkgload', 'plyr', 'processx',\n",
      "  'progressr', 'proxy', 'ps', 'purrr', 'quantmod', 'randomForest', 'rcmdcheck',\n",
      "  'RColorBrewer', 'Rcpp', 'RcppArmadillo', 'RCurl', 'readr', 'readxl',\n",
      "  'recipes', 'remotes', 'repr', 'reprex', 'rex', 'rlang', 'rmarkdown', 'RODBC',\n",
      "  'roxygen2', 'rpart', 'rprojroot', 'rsample', 'RSQLite', 'rstudioapi',\n",
      "  'rversions', 'rvest', 'S4Vectors', 'sass', 'scales', 'sessioninfo',\n",
      "  'sevenbridges', 'shiny', 'stringi', 'stringr', 'survival', 'sys', 'testthat',\n",
      "  'tibble', 'tidymodels', 'tidyr', 'tidyselect', 'tidyverse', 'timeDate',\n",
      "  'tinytex', 'tseries', 'TTR', 'tune', 'tzdb', 'urca', 'usethis', 'uuid',\n",
      "  'vctrs', 'viridisLite', 'vroom', 'waldo', 'withr', 'workflows',\n",
      "  'workflowsets', 'xfun', 'xml2', 'xts', 'yaml', 'yardstick', 'zip', 'zoo'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if (!require(\"BiocManager\", quietly = TRUE))\n",
    "    install.packages(\"BiocManager\")\n",
    "BiocManager::install(version = \"3.14\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3340e5-8b57-4eab-8191-d12240296a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'getOption(\"repos\")' replaces Bioconductor standard repositories, see\n",
      "'?repositories' for details\n",
      "\n",
      "replacement repositories:\n",
      "    CRAN: https://cran.r-project.org\n",
      "\n",
      "\n",
      "Bioconductor version 3.14 (BiocManager 1.30.18), R 4.1.1 (2021-08-10)\n",
      "\n",
      "Installing package(s) 'biomaRt'\n",
      "\n",
      "also installing the dependencies ‘zlibbioc’, ‘GenomeInfoDbData’, ‘XVector’, ‘GenomeInfoDb’, ‘BiocGenerics’, ‘png’, ‘Biostrings’, ‘Biobase’, ‘IRanges’, ‘KEGGREST’, ‘filelock’, ‘XML’, ‘AnnotationDbi’, ‘BiocFileCache’\n",
      "\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n",
      "Old packages: 'backports', 'blob', 'brew', 'brio', 'broom', 'bslib', 'callr',\n",
      "  'caret', 'class', 'cli', 'clipr', 'colorspace', 'commonmark', 'conflicted',\n",
      "  'covr', 'cpp11', 'crayon', 'credentials', 'crosstalk', 'curl', 'data.table',\n",
      "  'DBI', 'dbplyr', 'desc', 'devtools', 'dials', 'diffobj', 'digest', 'dplyr',\n",
      "  'DT', 'dtplyr', 'e1071', 'evaluate', 'fansi', 'farver', 'forcats', 'foreach',\n",
      "  'forecast', 'fs', 'furrr', 'future', 'future.apply', 'gargle', 'generics',\n",
      "  'gert', 'ggplot2', 'gh', 'git2r', 'gitcreds', 'globals', 'glue',\n",
      "  'googlesheets4', 'gower', 'gtable', 'hardhat', 'haven', 'hms', 'htmltools',\n",
      "  'httpuv', 'httr', 'infer', 'ipred', 'IRdisplay', 'IRkernel', 'isoband',\n",
      "  'iterators', 'jsonlite', 'knitr', 'later', 'lattice', 'lhs', 'lifecycle',\n",
      "  'lmtest', 'lubridate', 'magrittr', 'MASS', 'Matrix', 'memoise', 'mgcv',\n",
      "  'mime', 'modeldata', 'modelr', 'nlme', 'nnet', 'objectProperties',\n",
      "  'objectSignals', 'openssl', 'parallelly', 'parsnip', 'patchwork', 'pbdZMQ',\n",
      "  'pillar', 'pkgbuild', 'pkgload', 'plyr', 'processx', 'progressr', 'proxy',\n",
      "  'ps', 'purrr', 'quantmod', 'randomForest', 'rcmdcheck', 'RColorBrewer',\n",
      "  'Rcpp', 'RcppArmadillo', 'RCurl', 'readr', 'readxl', 'recipes', 'remotes',\n",
      "  'repr', 'reprex', 'rex', 'rlang', 'rmarkdown', 'RODBC', 'roxygen2', 'rpart',\n",
      "  'rprojroot', 'rsample', 'RSQLite', 'rstudioapi', 'rversions', 'rvest',\n",
      "  'S4Vectors', 'sass', 'scales', 'sessioninfo', 'sevenbridges', 'shiny',\n",
      "  'stringi', 'stringr', 'survival', 'sys', 'testthat', 'tibble', 'tidymodels',\n",
      "  'tidyr', 'tidyselect', 'tidyverse', 'timeDate', 'tinytex', 'tseries', 'TTR',\n",
      "  'tune', 'tzdb', 'urca', 'usethis', 'uuid', 'vctrs', 'viridisLite', 'vroom',\n",
      "  'waldo', 'withr', 'workflows', 'workflowsets', 'xfun', 'xml2', 'xts', 'yaml',\n",
      "  'yardstick', 'zip', 'zoo'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BiocManager::install(\"biomaRt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae91c4a7-6dc4-4b7b-a0f3-445281753dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "BiocManager::install(\"DESeq2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a60bc9-e583-4d3d-ad1c-0706740fe6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(DESeq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d10168-4933-411c-98f7-289eb247447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"devtools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05532e3f-6097-4f15-816b-6571a5993a91",
   "metadata": {},
   "source": [
    "#### First time through - Received a Warning that rhdf5 not available for this version of R\n",
    "\n",
    "Looked up our version and google searched R 4.1.1 rhdf5\n",
    "    \n",
    "Can install using `BiocManager::install(\"rhdf5\")`\n",
    "\n",
    "Pactherlab says to install `*rhdf5*` first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a43a9e1-7ce6-4b68-860b-5e3e1876ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BiocManager::install(\"rhdf5\", force=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b03ce8-e5d8-4be8-be2b-e40c428d4541",
   "metadata": {},
   "outputs": [],
   "source": [
    "library (rhdf5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f66a8d-241c-4f86-8b23-3fcf14859d4f",
   "metadata": {},
   "source": [
    "#### Issues\n",
    "\n",
    "Noted in issues https://github.com/pachterlab/sleuth/issues/259 -- follow the instructions from [Paast](https://github.com/pachterlab/sleuth/issues/259#issuecomment-966270599)\n",
    "\n",
    "Install rhdf5 as noted above.\n",
    "\n",
    "Load the library\n",
    "\n",
    "##### Clone sleuth and install after editing the file\n",
    "\n",
    "Change directory to the top working directory in this etheral machine.\n",
    "\n",
    "```bash\n",
    "cd /sbgenomics/workspace\n",
    "```\n",
    "\n",
    "now clone the library \n",
    "\n",
    "```bash\n",
    "git clone https://github.com/pachterlab/sleuth.git\n",
    "```\n",
    "\n",
    "edit NAMESPACE as the instructions note - to remove the dependency remove the last line to remove the reference to **rhdf5**\n",
    "\n",
    "And then run the install.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace19ad-5aea-475b-8fe2-d6cc962eeba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "devtools::install('../../sleuth/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69aba07-0138-427f-a8e8-a28bd30b8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(sleuth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5947268-42ff-49ef-903b-980d1427b68a",
   "metadata": {},
   "source": [
    "We have successfully run Kallisto with Kallisto Quantitation.\n",
    "\n",
    "Results may be found after running an application on Cavatica here:\n",
    "\n",
    "```bash\n",
    "/sbgenomics/project-files/\n",
    "```\n",
    "\n",
    "For this analysis we will use the results from the run using `metadata_ten_samples_only_txt`\n",
    "\n",
    "Results are in:\n",
    "\n",
    "```bash\n",
    "/sbgenomics/project-files/ten_samples_expression_matrix.tpm.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7bc5b5-9e72-4bb8-92bd-d24143bb2479",
   "metadata": {},
   "source": [
    "### Parsing metadata\n",
    "\n",
    "A sleuth analysis is dependent on a metadata file, which describes the experimental design, the sample names, conditions and covariates. The metadata file is external to sleuth, and must be prepared prior to analysis. A metadata file should have been downloaded along with the kallisto quantifications. The first step in a sleuth analysis is loading of the metadata file. You might need the path in read_table below to where you have downloaded the kallisto dataset, so that the path directs to the sample_table.txt. We then select the relevant columns of the metadata.\n",
    "\n",
    "In our case, I used:\n",
    "\n",
    "```bash\n",
    "/sbgenomics/project-files/metadata_ten_samples_only.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a430a324-b6b5-4255-81eb-b15734e115bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata <- read.table('/sbgenomics/project-files/metadata_ten_samples_only.csv', sep=\",\", header=TRUE, stringsAsFactors = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809234a4-57cf-441d-a2c4-e1fd97127e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(metadata, n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d55633-bf9e-4b00-90d0-ef75788cef3a",
   "metadata": {},
   "source": [
    "There is an error in the last sample detail - where the paired should read `2` and not NA.  So I copied the file to a local directory and corrected it -- it is corrected permanently now - but for this run through you can see:\n",
    "```bash\n",
    "cp /sbgenomics/project-files/metadata_ten_samples_only.csv /sbgenomics/workspace/pediatric-DS-AML-TAM-Analysis/data\n",
    "```\n",
    "\n",
    "where I edited the file and now will read this one in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94ba4a-a191-494e-b2ed-d589c47843c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata <- read.table('/sbgenomics/workspace/pediatric-DS-AML-TAM-Analysis/data/metadata_ten_samples_only.csv', sep=\",\", header=TRUE, stringsAsFactors = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79d1bc-1a14-48c8-a57a-83f8116bd9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9209ebbd-dcfa-49b7-bb8e-413004406e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907e43b-7a13-47bf-8aad-dc88eb09f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata <- dplyr::select(metadata, c('Case.ID', 'Sample.ID', 'Gender', 'Disease.type', 'Abundance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea7756a-b5e7-4707-909c-10de1fefc960",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be16242-cd08-413b-a17e-8958d431c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata <- dplyr::distinct(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a9c46-262d-4daa-9c61-7c43ecde421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e4004-878f-4937-b888-ef9fd43f01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656197e-93f0-4008-b3bd-35c14adf1522",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata <- dplyr::rename(metadata, sample = Sample.ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0617541a-0664-46bf-896e-4838af463e9a",
   "metadata": {},
   "source": [
    "Need to rename a colump as well to `path` where we have `Abundance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e98d5a-534a-4021-bfed-ffa7768cd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata <- dplyr::rename(metadata, path = Abundance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc62a33-02e1-4fbb-9b80-6a53a66a41e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8ecb14-d688-47ec-bbee-c84bdc5bdb4d",
   "metadata": {},
   "source": [
    "#### biomaRt - how to use\n",
    "\n",
    "Following instructions from the [ensembl site](https://grch37.ensembl.org/info/data/biomart/biomart_r_package.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b315a983-b7eb-47c5-a618-3558f1988f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(biomaRt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b61ce-eaf9-4ede-b84f-a498ab0e16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mart <- biomaRt::useMart(biomart=\"ensembl\", \n",
    "                     dataset = \"hsapiens_gene_ensembl\",\n",
    "                        host = \"https://useast.ensembl.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a5d947-397f-46de-a8e6-88658fb08d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttg <- biomaRt::getBM(\n",
    "  attributes = c(\"ensembl_transcript_id\", \"transcript_version\",\n",
    "  \"ensembl_gene_id\", \"external_gene_name\", \"description\",\n",
    "  \"transcript_biotype\"),\n",
    "  mart = mart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386de62-67da-4ca9-a0d4-d5d7ad831a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttg <- dplyr::rename(ttg, target_id = ensembl_transcript_id,\n",
    "  ens_gene = ensembl_gene_id, ext_gene = external_gene_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0521385a-1bd1-402f-a9b0-53b52a1a4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttg <- dplyr::select(ttg, c('target_id', 'ens_gene', 'ext_gene'))\n",
    "head(ttg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d913a41-9424-440e-8f8d-218c8001fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttg <- read.table('/sbgenomics/workspace/pediatric-DS-AML-TAM-Analysis/data/ttg.csv', sep=\",\", header=TRUE, stringsAsFactors = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09c920-8118-4f34-a303-68e07003a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(ttg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad386e6-6c48-4e78-94f2-dc2b76581643",
   "metadata": {},
   "source": [
    "The resulting table contains Ensembl gene names (‘ens_gene’) and the associated transcripts (‘target_id’). Note that the gene-transcript mapping must be compatible with the transcriptome used with kallisto. In other words, to use Ensembl transcript-gene associations kallisto was run using the Ensembl transcriptome.\n",
    "\n",
    "#### Preparing the analysis\n",
    "\n",
    "The next step is to build a sleuth object. The sleuth object contains specification of the experimental design, a map describing grouping of transcripts into genes (or other groups), and a number of user specific parameters. In the example that follows, metadata is the experimental design and target_mapping describes the transcript groupings into genes previously constructed. Furthermore, we provide an aggregation_column, the column name of in ‘target_mapping’ table that is used to aggregate the transcripts. When both ‘target_mapping’ and ‘aggregation_column’ are provided, sleuth will automatically run in gene mode, returning gene differential expression results that came from the aggregation of transcript p-values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d1dce-7746-4fee-a4ab-7af9d5a84aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttg      <- data.frame(ttg)\n",
    "metadata <- data.frame(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92622045-2bc5-4756-bf26-218a3244c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(ttg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a5e33-2837-4687-ab45-8786e87e4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c20432-066b-4499-add6-71ea21f8fcf7",
   "metadata": {},
   "source": [
    "#### Model (Design) Matrix Required\n",
    "We need to supply a model matrix -- and Sleuth implicitly uses DESeq2\n",
    "\n",
    "[How to use DESeq2](https://www.bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html)\n",
    "\n",
    "We have the following to compare condition effects of gender (Male, Female) with Disease type(TAM, DS-AML) in our cases.\n",
    "\n",
    "We have two groups (Male, Female) and two conditions (TAM, DS-AML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e229a-213b-4b33-93f7-f6339b5fbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "group <- factor(metadata$Gender)\n",
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d9e6f1-af6d-47be-8b30-16a56c3cb5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition <- factor(metadata$Disease.type)\n",
    "condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e11dd7-998d-46b0-aca7-16011214d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model <- model.matrix(~group + condition + group:condition)\n",
    "full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a88a3-6c2f-457f-8b46-8a577f42de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_to_covariates = metadata\n",
    "target_mapping = ttg\n",
    "aggregation_column = \"ens_gene\"\n",
    "gene_mode = TRUE\n",
    "extra_bootstrap_summary = TRUE\n",
    "read_bootstrap_tpm = TRUE\n",
    "full_model = full_model\n",
    "normalize = TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5946281-e3e5-4868-ba3f-7a06e83bd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_opts <- list(gene_mode, extra_bootstrap_summary, read_bootstrap_tpm, full_model, normalize)\n",
    "names(extra_opts) <- c(\"gene_mode\",\n",
    "                       \"extra_bootstrap_summary\", \n",
    "                       \"read_bootstrap_tpm\", \n",
    "                       \"full_model\",\n",
    "                       \"normalize\")\n",
    "  if (\"extra_bootstrap_summary\" %in% names(extra_opts)) {\n",
    "    extra_bootstrap_summary <- extra_opts$extra_bootstrap_summary\n",
    "  } else {\n",
    "    extra_bootstrap_summary <- FALSE\n",
    "  }\n",
    "  if (\"read_bootstrap_tpm\" %in% names(extra_opts)) {\n",
    "    read_bootstrap_tpm <- extra_opts$read_bootstrap_tpm\n",
    "  } else {\n",
    "    read_bootstrap_tpm <- FALSE\n",
    "  }\n",
    "  if (\"max_bootstrap\" %in% names(extra_opts)) {\n",
    "    max_bootstrap <- extra_opts$max_bootstrap\n",
    "  } else {\n",
    "    max_bootstrap <- NULL\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eaaa55-a668-4ef6-911b-788472fd7e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_bootstrap_summary\n",
    "read_bootstrap_tpm\n",
    "max_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae46d60c-45f5-4cd2-8e48-c561bcab177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names(extra_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f090924-7335-4626-9bd0-a9e3d46db878",
   "metadata": {},
   "outputs": [],
   "source": [
    "so <- sleuth_prep(sample_to_covariates    = metadata, \n",
    "                  target_mapping          = ttg, \n",
    "                  aggregation_column      = 'ens_gene',\n",
    "                  gene_mode               = TRUE,\n",
    "                  extra_bootstrap_summary = TRUE,\n",
    "                  read_bootstrap_tpm      = TRUE,\n",
    "                  full_model              = full_model,\n",
    "                  normalize               = TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b2528-36a5-47da-a298-efab33f94241",
   "metadata": {},
   "source": [
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4442bf52-6431-47e9-877f-7987ad4055b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttg.df <- data.frame (ttg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc64998-e3ff-4295-9cd7-21121236ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "  sample_to_covariates <- as.data.frame(sample_to_covariates)\n",
    "  sample_to_covariates$sample <- as.character(sample_to_covariates$sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb6456-3a3c-4f4e-a29a-e9daddacf867",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(sample_to_covariates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
